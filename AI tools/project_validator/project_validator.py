#!/usr/bin/env python3
"""
project_validator.py
====================

–í–∞–ª–∏–¥–∞—Ç–æ—Ä Python –ø—Ä–æ–µ–∫—Ç–æ–≤.
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç: —Å–∏–Ω—Ç–∞–∫—Å–∏—Å, —Å—Ç–∏–ª—å –∫–æ–¥–∞, —Å—Ç—Ä—É–∫—Ç—É—Ä—É, –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏, –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python project_validator.py [–ø—É—Ç—å_–∫_–ø—Ä–æ–µ–∫—Ç—É] [--format json|text|github]
"""

import os
import ast
import sys
import json
from pathlib import Path
from typing import Dict, List, Set, Any, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum
import argparse
import datetime


class IssueSeverity(Enum):
    ERROR = "ERROR"
    WARNING = "WARNING"
    INFO = "INFO"


@dataclass
class ValidationIssue:
    """–ü—Ä–æ–±–ª–µ–º–∞, –Ω–∞–π–¥–µ–Ω–Ω–∞—è –ø—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
    file_path: str
    line: Optional[int] = None
    column: Optional[int] = None
    severity: IssueSeverity = IssueSeverity.WARNING
    code: str = ""
    message: str = ""
    suggestion: str = ""


@dataclass
class ValidationResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞"""
    total_files: int = 0
    valid_files: int = 0
    issues_by_severity: Dict[IssueSeverity, List[ValidationIssue]] = field(
        default_factory=lambda: {s: [] for s in IssueSeverity}
    )
    issues_by_category: Dict[str, List[ValidationIssue]] = field(default_factory=dict)
    stats: Dict[str, Any] = field(default_factory=dict)
    line_stats: Dict[str, Any] = field(default_factory=dict)  # –ù–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å—Ç—Ä–æ–∫–∞–º


class IssueFilter:
    """–§–∏–ª—å—Ç—Ä –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤—ã–≤–æ–¥–æ–º –ø—Ä–æ–±–ª–µ–º"""

    def __init__(self, config: Dict):
        self.config = config
        self.filters = self._parse_filters()

    def _parse_filters(self) -> Dict:
        """–ü–∞—Ä—Å–∏—Ç —Ñ–∏–ª—å—Ç—Ä—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞"""
        filters = {
            "min_severity": IssueSeverity.INFO,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å
            "max_issues_per_file": 10,  # –ú–∞–∫—Å–∏–º—É–º –ø—Ä–æ–±–ª–µ–º –Ω–∞ —Ñ–∞–π–ª
            "max_issues_per_category": 50,  # –ú–∞–∫—Å–∏–º—É–º –ø—Ä–æ–±–ª–µ–º –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—é
            "ignore_patterns": [],  # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è
            "show_all": False,  # –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –≤—Å–µ –ø—Ä–æ–±–ª–µ–º—ã
        }

        # –û–±–Ω–æ–≤–ª—è–µ–º –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        filters.update(self.config.get("filters", {}))
        return filters

    def filter_issues(self, issues: List[ValidationIssue]) -> List[ValidationIssue]:
        """–§–∏–ª—å—Ç—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–±–ª–µ–º"""
        if self.filters["show_all"]:
            return issues

        filtered = []
        issues_by_file = {}

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ñ–∞–π–ª–∞–º
        for issue in issues:
            if issue.file_path not in issues_by_file:
                issues_by_file[issue.file_path] = []
            issues_by_file[issue.file_path].append(issue)

        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
        for file_path, file_issues in issues_by_file.items():
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏ (ERROR > WARNING > INFO)
            file_issues.sort(key=lambda x: (x.severity.value, x.line or 0))

            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–±–ª–µ–º –Ω–∞ —Ñ–∞–π–ª
            limited_issues = file_issues[:self.filters["max_issues_per_file"]]

            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –≤–∞–∂–Ω–æ—Å—Ç–∏
            for issue in limited_issues:
                if self._should_show_issue(issue):
                    filtered.append(issue)

        return filtered

    def _should_show_issue(self, issue: ValidationIssue) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø—Ä–æ–±–ª–µ–º—É"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –≤–∞–∂–Ω–æ—Å—Ç—å
        severity_order = {IssueSeverity.ERROR: 3, IssueSeverity.WARNING: 2, IssueSeverity.INFO: 1}
        min_order = severity_order.get(self.filters["min_severity"], 1)
        issue_order = severity_order.get(issue.severity, 0)

        if issue_order < min_order:
            return False

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è
        for pattern in self.filters["ignore_patterns"]:
            if pattern in issue.code or pattern in issue.message:
                return False

        return True


class ProjectValidator:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–∞ –ø—Ä–æ–µ–∫—Ç–æ–≤"""

    def __init__(self, project_root: str = ".", config: Optional[Dict] = None):
        self.project_root = Path(project_root).resolve()
        self.config = config or self._default_config()
        self.ignored_dirs = self.config.get("ignored_dirs", ['.git', '__pycache__', 'venv'])
        self.ignored_files = self.config.get("ignored_files", [])

    def _default_config(self) -> Dict:
        """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
        return {
            "ignored_dirs": ['.git', '__pycache__', 'venv', 'env', '.venv', 'node_modules'],
            "ignored_files": ['.DS_Store', 'thumbs.db'],
            "max_file_size_kb": 100,
            "max_line_length": 120,
            "max_function_lines": 50,
            "max_nesting_depth": 5,
            "check_security": True,
            "check_performance": True,
            "check_style": True,
            "enforce_type_hints": False,
            "require_docstrings": False,
            "output_file": "validation_report.txt",
        }

    def validate_project(self) -> ValidationResult:
        """–ü–æ–ª–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞"""
        print(f"üîç –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞: {self.project_root}")

        result = ValidationResult()
        all_issues = []
        line_stats = {
            "total_lines": 0,
            "max_lines": 0,
            "min_lines": float('inf'),
            "file_line_counts": {},
            "avg_lines_per_file": 0
        }

        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ Python —Ñ–∞–π–ª—ã
        python_files = self._find_all_python_files()
        result.total_files = len(python_files)

        if result.total_files == 0:
            print("‚ö†Ô∏è  –ù–µ –Ω–∞–π–¥–µ–Ω–æ Python —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
            return result

        print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {result.total_files}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª –∏ —Å–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Å—Ç—Ä–æ–∫–∞–º
        for file_path in python_files:
            rel_path = str(file_path.relative_to(self.project_root))

            # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Å—Ç—Ä–æ–∫–∞–º
            file_line_count = self._count_file_lines(file_path)
            line_stats["total_lines"] += file_line_count
            line_stats["max_lines"] = max(line_stats["max_lines"], file_line_count)
            line_stats["min_lines"] = min(line_stats["min_lines"], file_line_count)
            line_stats["file_line_counts"][rel_path] = file_line_count

            file_issues = self._validate_file(file_path)
            all_issues.extend(file_issues)

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫
        if result.total_files > 0:
            line_stats["avg_lines_per_file"] = line_stats["total_lines"] / result.total_files

        result.line_stats = line_stats

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø—Ä–æ–±–ª–µ–º—ã
        result.issues_by_category = self._categorize_issues(all_issues)
        for severity in IssueSeverity:
            result.issues_by_severity[severity] = [
                issue for issue in all_issues if issue.severity == severity
            ]

        # –°—á–∏—Ç–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        error_issues = result.issues_by_severity[IssueSeverity.ERROR]
        files_with_errors = len({issue.file_path for issue in error_issues})

        result.valid_files = result.total_files - files_with_errors

        result.stats = {
            "error_count": len(error_issues),
            "warning_count": len(result.issues_by_severity[IssueSeverity.WARNING]),
            "info_count": len(result.issues_by_severity[IssueSeverity.INFO]),
            "files_with_errors": files_with_errors,
            "files_with_warnings": len({issue.file_path for issue in result.issues_by_severity[IssueSeverity.WARNING]}),
            "files_with_info": len({issue.file_path for issue in result.issues_by_severity[IssueSeverity.INFO]}),
        }

        return result

    def _count_file_lines(self, file_path: Path) -> int:
        """–°—á–∏—Ç–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –≤ —Ñ–∞–π–ª–µ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return sum(1 for _ in f)
        except:
            return 0

    def _find_all_python_files(self) -> List[Path]:
        """–ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ Python —Ñ–∞–π–ª—ã –≤ –ø—Ä–æ–µ–∫—Ç–µ"""
        python_files = []

        for root, dirs, files in os.walk(self.project_root):
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            dirs[:] = [d for d in dirs if d not in self.ignored_dirs and not d.startswith('.')]

            for file in files:
                if file.endswith('.py') and file not in self.ignored_files:
                    python_files.append(Path(root) / file)

        return python_files

    def _validate_file(self, file_path: Path) -> List[ValidationIssue]:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª"""
        issues = []
        rel_path = str(file_path.relative_to(self.project_root))

        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
        issues.extend(self._check_file_size(file_path))

        # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            try:
                tree = ast.parse(content, filename=str(file_path))
            except SyntaxError as e:
                issues.append(ValidationIssue(
                    file_path=rel_path,
                    line=e.lineno,
                    column=e.offset,
                    severity=IssueSeverity.ERROR,
                    code="SYNTAX_ERROR",
                    message=f"–°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e.msg}",
                    suggestion="–ò—Å–ø—Ä–∞–≤—å—Ç–µ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å Python"
                ))
                return issues  # –ù–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–ª—å—à–µ —Ñ–∞–π–ª—ã —Å —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏

            # 3. –ü—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ AST
            if self.config.get("check_style", True):
                issues.extend(self._check_ast_issues(tree, file_path))

            if self.config.get("check_security", True):
                issues.extend(self._check_security_issues(tree, file_path))

            # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∏–ª—è –∫–æ–¥–∞
            issues.extend(self._check_code_style(content, file_path))

            # 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            if self.config.get("check_performance", True):
                issues.extend(self._check_performance_issues(tree, file_path))

        except (UnicodeDecodeError, PermissionError) as e:
            issues.append(ValidationIssue(
                file_path=rel_path,
                severity=IssueSeverity.ERROR,
                code="FILE_READ_ERROR",
                message=f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª: {e}",
                suggestion="–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ –∏ –∫–æ–¥–∏—Ä–æ–≤–∫—É —Ñ–∞–π–ª–∞"
            ))

        return issues

    def _check_file_size(self, file_path: Path) -> List[ValidationIssue]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞"""
        issues = []
        rel_path = str(file_path.relative_to(self.project_root))

        max_size_kb = self.config.get("max_file_size_kb", 100)
        file_size_kb = file_path.stat().st_size / 1024

        if file_size_kb > max_size_kb:
            issues.append(ValidationIssue(
                file_path=rel_path,
                severity=IssueSeverity.WARNING,
                code="FILE_TOO_LARGE",
                message=f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π: {file_size_kb:.1f}KB (–º–∞–∫—Å: {max_size_kb}KB)",
                suggestion="–†–∞–∑–±–µ–π—Ç–µ —Ñ–∞–π–ª –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥—É–ª–µ–π"
            ))

        return issues

    def _check_ast_issues(self, tree: ast.AST, file_path: Path) -> List[ValidationIssue]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã –Ω–∞ —É—Ä–æ–≤–Ω–µ AST"""
        issues = []
        rel_path = str(file_path.relative_to(self.project_root))

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ª–∏—à–∫–æ–º –≥–ª—É–±–æ–∫—É—é –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç—å
        max_depth = self.config.get("max_nesting_depth", 5)

        class DepthChecker(ast.NodeVisitor):
            def __init__(self):
                self.max_depth = 0
                self.current_depth = 0
                self.issues = []

            def visit_FunctionDef(self, node):
                self.current_depth += 1
                if self.current_depth > max_depth:
                    self.issues.append(ValidationIssue(
                        file_path=rel_path,
                        line=node.lineno,
                        severity=IssueSeverity.WARNING,
                        code="DEEP_NESTING",
                        message=f"–°–ª–∏—à–∫–æ–º –≥–ª—É–±–æ–∫–∞—è –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç—å: {self.current_depth} —É—Ä–æ–≤–Ω–µ–π",
                        suggestion="–†–µ—Ñ–∞–∫—Ç–æ—Ä–∏—Ç–µ –∫–æ–¥, –≤—ã–¥–µ–ª–∏—Ç–µ —á–∞—Å—Ç–∏ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏"
                    ))
                self.generic_visit(node)
                self.current_depth -= 1

            def visit_ClassDef(self, node):
                self.current_depth += 1
                self.generic_visit(node)
                self.current_depth -= 1

        checker = DepthChecker()
        checker.visit(tree)
        issues.extend(checker.issues)

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
        max_lines = self.config.get("max_function_lines", 50)

        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                # –°—á–∏—Ç–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –≤ —Ñ—É–Ω–∫—Ü–∏–∏
                func_lines = node.end_lineno - node.lineno + 1 if node.end_lineno else 0

                if func_lines > max_lines:
                    issues.append(ValidationIssue(
                        file_path=rel_path,
                        line=node.lineno,
                        severity=IssueSeverity.WARNING,
                        code="FUNCTION_TOO_LONG",
                        message=f"–§—É–Ω–∫—Ü–∏—è —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–∞—è: {func_lines} —Å—Ç—Ä–æ–∫",
                        suggestion=f"–†–∞–∑–±–µ–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é –Ω–∞ —á–∞—Å—Ç–∏ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ {max_lines} —Å—Ç—Ä–æ–∫)"
                    ))

        return issues

    def _check_security_issues(self, tree: ast.AST, file_path: Path) -> List[ValidationIssue]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —É—è–∑–≤–∏–º–æ—Å—Ç–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"""
        issues = []
        rel_path = str(file_path.relative_to(self.project_root))

        dangerous_functions = {
            'eval': '–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ eval() –æ–ø–∞—Å–Ω–æ',
            'exec': '–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ exec() –æ–ø–∞—Å–Ω–æ',
            'pickle.loads': '–î–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è pickle –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–ø–∞—Å–Ω–∞',
            'yaml.load': '–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ yaml.safe_load()',
            'subprocess.Popen': '–ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏',
            'os.system': '–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ subprocess —Å –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏',
        }

        for node in ast.walk(tree):
            if isinstance(node, ast.Call):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—ã–∑–æ–≤—ã –æ–ø–∞—Å–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π
                func_name = self._get_function_name(node.func)
                if func_name in dangerous_functions:
                    issues.append(ValidationIssue(
                        file_path=rel_path,
                        line=node.lineno,
                        severity=IssueSeverity.WARNING,
                        code="SECURITY_RISK",
                        message=dangerous_functions[func_name],
                        suggestion="–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"
                    ))

        return issues

    @staticmethod
    def _get_function_name(node: ast.AST) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–º—è —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ AST —É–∑–ª–∞"""
        match node:
            case ast.Name():
                return node.id
            case ast.Attribute():
                if isinstance(node.value, ast.Name):
                    return f"{node.value.id}.{node.attr}"
        return ""

    def _check_code_style(self, content: str, file_path: Path) -> List[ValidationIssue]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∏–ª—å –∫–æ–¥–∞"""
        issues = []
        rel_path = str(file_path.relative_to(self.project_root))
        lines = content.split('\n')

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã —Å—Ç—Ä–æ–∫
        max_line_length = self.config.get("max_line_length", 120)
        for i, line in enumerate(lines, 1):
            if len(line) > max_line_length:
                issues.append(ValidationIssue(
                    file_path=rel_path,
                    line=i,
                    severity=IssueSeverity.WARNING,
                    code="LINE_TOO_LONG",
                    message=f"–°—Ç—Ä–æ–∫–∞ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–∞—è: {len(line)} —Å–∏–º–≤–æ–ª–æ–≤",
                    suggestion=f"–†–∞–∑–±–µ–π—Ç–µ —Å—Ç—Ä–æ–∫—É (–º–∞–∫—Å: {max_line_length} —Å–∏–º–≤–æ–ª–æ–≤)"
                ))

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–º–µ—à–∏–≤–∞–Ω–∏–µ —Ç–∞–±–æ–≤ –∏ –ø—Ä–æ–±–µ–ª–æ–≤
        if '\t' in content and '    ' in content:
            issues.append(ValidationIssue(
                file_path=rel_path,
                severity=IssueSeverity.ERROR,
                code="MIXED_INDENTATION",
                message="–°–º–µ—à–∞–Ω—ã —Ç–∞–±—ã –∏ –ø—Ä–æ–±–µ–ª—ã –¥–ª—è –æ—Ç—Å—Ç—É–ø–æ–≤",
                suggestion="–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–æ–ª—å–∫–æ –ø—Ä–æ–±–µ–ª—ã (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 4 –ø—Ä–æ–±–µ–ª–∞)"
            ))

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ trailing whitespace
        for i, line in enumerate(lines, 1):
            if line.endswith(' ') or line.endswith('\t'):
                issues.append(ValidationIssue(
                    file_path=rel_path,
                    line=i,
                    severity=IssueSeverity.WARNING,
                    code="TRAILING_WHITESPACE",
                    message="–õ–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –≤ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫–∏",
                    suggestion="–£–¥–∞–ª–∏—Ç–µ –ø—Ä–æ–±–µ–ª—ã –≤ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫–∏"
                ))

        return issues

    def _check_performance_issues(self, tree: ast.AST, file_path: Path) -> List[ValidationIssue]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        issues = []
        rel_path = str(file_path.relative_to(self.project_root))

        for node in ast.walk(tree):
            match node:
                case ast.For(iter=ast.Call(func=ast.Name(id='range'), args=[ast.Call(func=ast.Name(id='len'))])):
                    # range(len(...)) –≤ —Ü–∏–∫–ª–µ for
                    issues.append(ValidationIssue(
                        file_path=rel_path,
                        line=node.lineno,
                        severity=IssueSeverity.INFO,
                        code="INEFFICIENT_RANGE",
                        message="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ range(len(...)) –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–º",
                        suggestion="–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ enumerate() –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –∏–Ω–¥–µ–∫—Å–∞–º –∏ –∑–Ω–∞—á–µ–Ω–∏—è–º"
                    ))

                case ast.For(iter=ast.Call(func=ast.Name(id='range'), args=[ast.Call(func=ast.Name(id='len'))] as args)) if len(args) == 1:
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è range(len(...))
                    issues.append(ValidationIssue(
                        file_path=rel_path,
                        line=node.lineno,
                        severity=IssueSeverity.INFO,
                        code="INEFFICIENT_RANGE",
                        message="range(len(...)) –≤–º–µ—Å—Ç–æ enumerate()",
                        suggestion="–ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ enumerate(iterable) –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏"
                    ))

                case ast.ListComp() | ast.SetComp() | ast.DictComp() as comp:
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–ª–æ–∂–Ω—ã—Ö –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤
                    if len(comp.generators) > 2:
                        issues.append(ValidationIssue(
                            file_path=rel_path,
                            line=node.lineno,
                            severity=IssueSeverity.INFO,
                            code="COMPLEX_COMPREHENSION",
                            message="–°–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ-–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä",
                            suggestion="–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –æ–±—ã—á–Ω—ã—Ö —Ü–∏–∫–ª–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏"
                        ))

                case ast.Call(func=ast.Attribute(value=ast.Name(id='re'), attr='compile')) if len(node.args) > 0:
                    # –ö–æ–º–ø–∏–ª—è—Ü–∏—è regex –≤ —Ü–∏–∫–ª–µ
                    for parent in ast.walk(tree):
                        if isinstance(parent, (ast.For, ast.While)) and node in ast.walk(parent):
                            issues.append(ValidationIssue(
                                file_path=rel_path,
                                line=node.lineno,
                                severity=IssueSeverity.WARNING,
                                code="REGEX_IN_LOOP",
                                message="–ö–æ–º–ø–∏–ª—è—Ü–∏—è —Ä–µ–≥—É–ª—è—Ä–Ω–æ–≥–æ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –≤–Ω—É—Ç—Ä–∏ —Ü–∏–∫–ª–∞",
                                suggestion="–í—ã–Ω–µ—Å–∏—Ç–µ re.compile() –∑–∞ –ø—Ä–µ–¥–µ–ª—ã —Ü–∏–∫–ª–∞"
                            ))
                            break

                case ast.Call(func=ast.Name(id='list') | ast.Name(id='dict') | ast.Name(id='set') as func):
                    # –ò–∑–±—ã—Ç–æ—á–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–∏–ø–æ–≤
                    if len(node.args) == 1 and isinstance(node.args[0], (ast.List, ast.Dict, ast.Set)):
                        func_name = func.id
                        issues.append(ValidationIssue(
                            file_path=rel_path,
                            line=node.lineno,
                            severity=IssueSeverity.INFO,
                            code="REDUNDANT_CONVERSION",
                            message=f"–ò–∑–±—ã—Ç–æ—á–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ {func_name}(...)",
                            suggestion=f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ª–∏—Ç–µ—Ä–∞–ª –Ω–∞–ø—Ä—è–º—É—é –≤–º–µ—Å—Ç–æ {func_name}()"
                        ))

        return issues

    def _categorize_issues(self, issues: List[ValidationIssue]) -> Dict[str, List[ValidationIssue]]:
        """–ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º"""
        categories = {
            "syntax": [],
            "security": [],
            "performance": [],
            "style": [],
            "structure": [],
            "other": []
        }

        category_mapping = {
            "SYNTAX": "syntax",
            "SECURITY": "security",
            "PERFORMANCE": "performance",
            "INEFFICIENT": "performance",
            "REGEX": "performance",
            "COMPLEX": "performance",
            "REDUNDANT": "performance",
            "LINE": "style",
            "WHITESPACE": "style",
            "INDENTATION": "style",
            "FILE": "structure",
            "FUNCTION": "structure",
            "NESTING": "structure",
            "DEEP": "structure",
        }

        for issue in issues:
            assigned = False
            for keyword, category in category_mapping.items():
                if keyword in issue.code:
                    categories[category].append(issue)
                    assigned = True
                    break

            if not assigned:
                categories["other"].append(issue)

        return categories

    def check_dependencies(self) -> List[ValidationIssue]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –ø—Ä–æ–µ–∫—Ç–∞"""
        issues = []

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ requirements.txt
        req_file = self.project_root / "requirements.txt"
        if req_file.exists():
            try:
                with open(req_file, 'r') as f:
                    requirements = f.readlines()

                # –ü—Ä–æ—Å—Ç—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ requirements.txt
                for i, line in enumerate(requirements, 1):
                    line = line.strip()
                    if line and not line.startswith('#') and '==' not in line and line.count('>') < 2 and line.count('<') < 2:
                        issues.append(ValidationIssue(
                            file_path="requirements.txt",
                            line=i,
                            severity=IssueSeverity.WARNING,
                            code="LOOSE_DEPENDENCY",
                            message=f"–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –±–µ–∑ –≤–µ—Ä—Å–∏–∏: {line}",
                            suggestion="–£–∫–∞–∂–∏—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –≤–µ—Ä—Å–∏—é –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (–Ω–∞–ø—Ä. 'package==1.0.0')"
                        ))
            except Exception as e:
                issues.append(ValidationIssue(
                    file_path="requirements.txt",
                    severity=IssueSeverity.ERROR,
                    code="REQUIREMENTS_ERROR",
                    message=f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å requirements.txt: {e}",
                    suggestion="–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞"
                ))
        else:
            issues.append(ValidationIssue(
                file_path="requirements.txt",
                severity=IssueSeverity.WARNING,
                code="NO_REQUIREMENTS",
                message="–§–∞–π–ª requirements.txt –Ω–µ –Ω–∞–π–¥–µ–Ω",
                suggestion="–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª requirements.txt –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏"
            ))

        return issues


class ReportFormatter:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""

    @staticmethod
    def format_text(
            result: ValidationResult,
            verbose: bool = False,
            output_file: str = None,
            issue_filter: Optional[IssueFilter] = None
    ) -> str:
        """–¢–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç—á–µ—Ç–∞"""
        lines = []

        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        lines.append("=" * 70)
        lines.append(f"üìã –û–¢–ß–ï–¢ –í–ê–õ–ò–î–ê–¶–ò–ò –ü–†–û–ï–ö–¢–ê")
        lines.append(f"üìÖ {timestamp}")
        lines.append("=" * 70)

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞
        lines.append(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–†–û–ï–ö–¢–ê:")
        lines.append(f"  –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {result.total_files}")
        lines.append(f"  –í–∞–ª–∏–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {result.valid_files}")
        lines.append(f"  –û—à–∏–±–æ–∫: {result.stats.get('error_count', 0)}")
        lines.append(f"  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: {result.stats.get('warning_count', 0)}")
        lines.append(f"  –ó–∞–º–µ—á–∞–Ω–∏–π: {result.stats.get('info_count', 0)}")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å—Ç—Ä–æ–∫–∞–º
        if result.line_stats:
            lines.append(f"\nüìè –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –°–¢–†–û–ö–ê–ú:")
            lines.append(f"  –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {result.line_stats.get('total_lines', 0):,}")
            lines.append(f"  –°—Ä–µ–¥–Ω–µ–µ –Ω–∞ —Ñ–∞–π–ª: {result.line_stats.get('avg_lines_per_file', 0):.1f}")
            lines.append(f"  –ú–∞–∫—Å–∏–º—É–º: {result.line_stats.get('max_lines', 0):,}")
            lines.append(f"  –ú–∏–Ω–∏–º—É–º: {result.line_stats.get('min_lines', 0):,}")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-5 —Å–∞–º—ã—Ö –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
            file_counts = result.line_stats.get('file_line_counts', {})
            if file_counts:
                sorted_files = sorted(file_counts.items(), key=lambda x: x[1], reverse=True)[:5]
                lines.append(f"\n  üìà –¢–æ–ø-5 —Å–∞–º—ã—Ö –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤:")
                for file_path, count in sorted_files:
                    lines.append(f"    ‚Ä¢ {file_path}: {count:,} —Å—Ç—Ä–æ–∫")

        # –°—É–º–º–∞—Ä–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–æ–±–ª–µ–º–∞–º
        lines.append(f"\n‚ö†Ô∏è  –°–í–û–î–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–†–û–ë–õ–ï–ú:")

        # –ü—Ä–æ–±–ª–µ–º—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        for category, category_issues in sorted(result.issues_by_category.items()):
            if category_issues:
                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
                error_count = len([i for i in category_issues if i.severity == IssueSeverity.ERROR])
                warning_count = len([i for i in category_issues if i.severity == IssueSeverity.WARNING])
                info_count = len([i for i in category_issues if i.severity == IssueSeverity.INFO])

                severity_summary = []
                if error_count > 0:
                    severity_summary.append(f"‚ùå {error_count}")
                if warning_count > 0:
                    severity_summary.append(f"‚ö†Ô∏è  {warning_count}")
                if info_count > 0:
                    severity_summary.append(f"‚ÑπÔ∏è  {info_count}")

                severity_str = " | ".join(severity_summary)
                lines.append(f"  {category.upper():12} ({len(category_issues):4}) [{severity_str}]")

        lines.append(f"\nüìÅ –§–∞–π–ª–æ–≤ —Å –ø—Ä–æ–±–ª–µ–º–∞–º–∏:")
        lines.append(f"  –° –æ—à–∏–±–∫–∞–º–∏: {result.stats.get('files_with_errors', 0)}")
        lines.append(f"  –° –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏: {result.stats.get('files_with_warnings', 0)}")
        lines.append(f"  –° –∑–∞–º–µ—á–∞–Ω–∏—è–º–∏: {result.stats.get('files_with_info', 0)}")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–µ—Ç–∞–ª–∏ –ø–æ –ø—Ä–æ–±–ª–µ–º–∞–º (—Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π)
        lines.append(f"\nüîé –î–ï–¢–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –ü–û –ü–†–û–ë–õ–ï–ú–ê–ú:")

        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä –µ—Å–ª–∏ –µ—Å—Ç—å
        filtered_categories = {}
        for category, category_issues in result.issues_by_category.items():
            if issue_filter:
                filtered_categories[category] = issue_filter.filter_issues(category_issues)
            else:
                filtered_categories[category] = category_issues[:50]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

        for category, category_issues in filtered_categories.items():
            if category_issues:
                # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø—Ä–æ–±–ª–µ–º—ã –ø–æ —Ñ–∞–π–ª–∞–º
                issues_by_file = {}
                for issue in category_issues:
                    if issue.file_path not in issues_by_file:
                        issues_by_file[issue.file_path] = []
                    issues_by_file[issue.file_path].append(issue)

                if issues_by_file:
                    lines.append(f"\n  {category.upper()} ({len(category_issues)}):")

                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–±–ª–µ–º—ã –ø–æ —Ñ–∞–π–ª–∞–º
                    for file_path, file_issues in sorted(issues_by_file.items())[:15]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ñ–∞–π–ª—ã
                        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º –ø—Ä–æ–±–ª–µ–º
                        issues_by_type = {}
                        for issue in file_issues:
                            if issue.code not in issues_by_type:
                                issues_by_type[issue.code] = []
                            issues_by_type[issue.code].append(issue)

                        # –°–æ–∑–¥–∞–µ–º –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
                        type_summary = []
                        for code, type_issues in list(issues_by_type.items())[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 —Ç–∏–ø–∞
                            type_summary.append(f"{code}({len(type_issues)})")

                        if len(issues_by_type) > 3:
                            type_summary.append(f"...(+{len(issues_by_type) - 3})")

                        lines.append(f"    üìÑ {file_path}:")
                        lines.append(f"        –í—Å–µ–≥–æ –ø—Ä–æ–±–ª–µ–º: {len(file_issues)}")
                        lines.append(f"        –¢–∏–ø—ã: {', '.join(type_summary)}")

                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–±–ª–µ–º –µ—Å–ª–∏ verbose
                        if verbose:
                            for issue in file_issues[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 –ø—Ä–æ–±–ª–µ–º –∏–∑ —Ñ–∞–π–ª–∞
                                line_info = f" —Å—Ç—Ä–æ–∫–∞ {issue.line}" if issue.line else ""
                                severity_icon = {
                                    IssueSeverity.ERROR: "‚ùå",
                                    IssueSeverity.WARNING: "‚ö†Ô∏è",
                                    IssueSeverity.INFO: "‚ÑπÔ∏è"
                                }.get(issue.severity, "‚Ä¢")

                                lines.append(f"        {severity_icon} {issue.code}{line_info}: {issue.message}")
                                if issue.suggestion:
                                    lines.append(f"          üí° {issue.suggestion}")

        # –ï—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º—ã –±—ã–ª–∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        total_filtered_issues = sum(len(issues) for issues in filtered_categories.values())
        total_original_issues = sum(len(issues) for issues in result.issues_by_category.values())

        if total_filtered_issues < total_original_issues:
            lines.append(f"\nüìù –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:")
            lines.append(f"  –ü–æ–∫–∞–∑–∞–Ω–æ {total_filtered_issues} –∏–∑ {total_original_issues} –ø—Ä–æ–±–ª–µ–º")
            lines.append(f"  –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --show-all –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞")

        # –ò—Ç–æ–≥
        if result.stats.get('error_count', 0) == 0:
            lines.append("\n‚úÖ –ü–†–û–ï–ö–¢ –ü–†–û–®–ï–õ –ë–ê–ó–û–í–£–Æ –í–ê–õ–ò–î–ê–¶–ò–Æ")
        else:
            lines.append(f"\n‚ùå –ù–ê–ô–î–ï–ù–û {result.stats.get('error_count', 0)} –û–®–ò–ë–û–ö")
            lines.append("   –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø—Ä–∞–≤–∏—Ç—å –æ—à–∏–±–∫–∏ –ø–µ—Ä–µ–¥ –∫–æ–º–º–∏—Ç–æ–º")

        lines.append("\n" + "=" * 70)

        report_text = "\n".join(lines)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ
        if output_file:
            try:
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(report_text)
                print(f"\nüíæ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {output_file}")
            except Exception as e:
                print(f"\n‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—á–µ—Ç: {e}")

        return report_text

    @staticmethod
    def format_compact(result: ValidationResult) -> str:
        """–ö–æ–º–ø–∞–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç—á–µ—Ç–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ–±–∑–æ—Ä–∞"""
        lines = []

        lines.append("=" * 50)
        lines.append("üìä –ö–û–ú–ü–ê–ö–¢–ù–´–ô –û–¢–ß–ï–¢ –í–ê–õ–ò–î–ê–¶–ò–ò")
        lines.append("=" * 50)

        # –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        lines.append(f"\nüìÅ –§–∞–π–ª–æ–≤: {result.total_files}")
        lines.append(f"üìè –°—Ç—Ä–æ–∫: {result.line_stats.get('total_lines', 0):,}")

        # –ò–∫–æ–Ω–∫–∏ —Å—Ç–∞—Ç—É—Å–∞
        error_icon = "‚ùå" if result.stats.get('error_count', 0) > 0 else "‚úÖ"
        warning_icon = "‚ö†Ô∏è" if result.stats.get('warning_count', 0) > 0 else "‚úÖ"

        lines.append(f"\n{error_icon} –û—à–∏–±–æ–∫: {result.stats.get('error_count', 0)}")
        lines.append(f"{warning_icon} –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: {result.stats.get('warning_count', 0)}")

        # –°–∞–º—ã–µ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Ñ–∞–π–ª—ã
        if result.issues_by_category:
            # –ù–∞—Ö–æ–¥–∏–º —Ñ–∞–π–ª—ã —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—Ä–æ–±–ª–µ–º
            all_issues = []
            for category_issues in result.issues_by_category.values():
                all_issues.extend(category_issues)

            issues_by_file = {}
            for issue in all_issues:
                if issue.file_path not in issues_by_file:
                    issues_by_file[issue.file_path] = []
                issues_by_file[issue.file_path].append(issue)

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø—Ä–æ–±–ª–µ–º
            sorted_files = sorted(issues_by_file.items(), key=lambda x: len(x[1]), reverse=True)[:5]

            if sorted_files:
                lines.append(f"\nüî• –¢–æ–ø-5 –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤:")
                for file_path, file_issues in sorted_files:
                    error_count = len([i for i in file_issues if i.severity == IssueSeverity.ERROR])
                    warning_count = len([i for i in file_issues if i.severity == IssueSeverity.WARNING])

                    severity_str = ""
                    if error_count > 0:
                        severity_str += f"‚ùå{error_count} "
                    if warning_count > 0:
                        severity_str += f"‚ö†Ô∏è{warning_count}"

                    lines.append(f"  ‚Ä¢ {file_path}: {len(file_issues)} –ø—Ä–æ–±–ª–µ–º ({severity_str})")

        lines.append("\n" + "=" * 50)

        return "\n".join(lines)


# –û–±–Ω–æ–≤–∏–º main —Ñ—É–Ω–∫—Ü–∏—é
def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞"""
    parser = argparse.ArgumentParser(
        description="–í–∞–ª–∏–¥–∞—Ç–æ—Ä Python –ø—Ä–æ–µ–∫—Ç–æ–≤",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  python project_validator.py                    # –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
  python project_validator.py --compact          # –ö–æ–º–ø–∞–∫—Ç–Ω—ã–π –æ—Ç—á–µ—Ç
  python project_validator.py --show-all         # –ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ –ø—Ä–æ–±–ª–µ–º—ã (–±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏)
  python project_validator.py --min-severity WARNING  # –¢–æ–ª—å–∫–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –∏ –æ—à–∏–±–∫–∏
  python project_validator.py --ignore trailing  # –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å trailing whitespace
  python project_validator.py --output report.md # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∞–∫ markdown
        """
    )

    parser.add_argument("path", nargs="?", default=".", help="–ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É")
    parser.add_argument("--format", choices=["text", "json", "github", "compact"], default="text",
                        help="–§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: text)")
    parser.add_argument("--verbose", "-v", action="store_true", help="–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥")
    parser.add_argument("--compact", action="store_true", help="–ö–æ–º–ø–∞–∫—Ç–Ω—ã–π –æ—Ç—á–µ—Ç")
    parser.add_argument("--config", help="–ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É JSON")
    parser.add_argument("--output", "-o", help="–ò–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –¥–ª—è –æ—Ç—á–µ—Ç–∞")
    parser.add_argument("--no-save", action="store_true", help="–ù–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –æ—Ç—á–µ—Ç –≤ —Ñ–∞–π–ª")
    parser.add_argument("--show-all", action="store_true", help="–ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ –ø—Ä–æ–±–ª–µ–º—ã (–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)")
    parser.add_argument("--min-severity", choices=["ERROR", "WARNING", "INFO"], default="INFO",
                        help="–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º –¥–ª—è –ø–æ–∫–∞–∑–∞")
    parser.add_argument("--ignore", action="append", help="–ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–±–ª–µ–º—ã —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º –∫–æ–¥–æ–º")

    args = parser.parse_args()

    args.path = "C:\\Users\\Egor\\PycharmProjects\\ProjectMind\\ProjectMind\\ProjectMind-core"
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
    config = {}
    if args.config and Path(args.config).exists():
        try:
            with open(args.config, 'r') as f:
                config = json.load(f)
        except json.JSONDecodeError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥–∞: {e}")
            sys.exit(1)

    # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    if "filters" not in config:
        config["filters"] = {}

    config["filters"]["show_all"] = args.show_all
    if args.min_severity:
        config["filters"]["min_severity"] = IssueSeverity[args.min_severity]
    if args.ignore:
        config["filters"]["ignore_patterns"] = args.ignore

    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é
    validator = ProjectValidator(args.path, config)

    try:
        result = validator.validate_project()

        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        dep_issues = validator.check_dependencies()
        for issue in dep_issues:
            result.issues_by_severity[issue.severity].append(issue)
            # –¢–∞–∫–∂–µ –¥–æ–±–∞–≤–ª—è–µ–º –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—é
            result.issues_by_category.setdefault("dependencies", []).append(issue)

        # –°–æ–∑–¥–∞–µ–º —Ñ–∏–ª—å—Ç—Ä
        issue_filter = IssueFilter(config) if not args.show_all else None

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        output_filename = args.output or config.get("output_file", "validation_report.txt")

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
        if args.format == "json" or args.compact:
            output_file = None if args.no_save else output_filename.replace('.txt', '.json')
            report = ReportFormatter.format_json(result, output_file)
        elif args.format == "github":
            report = ReportFormatter.format_github_actions(result)
            if not args.no_save:
                with open("github_actions_report.txt", 'w', encoding='utf-8') as f:
                    f.write(report)
        elif args.compact:
            output_file = None if args.no_save else "validation_compact.txt"
            report = ReportFormatter.format_compact(result)
            if output_file and not args.no_save:
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(report)
        else:
            output_file = None if args.no_save else output_filename
            report = ReportFormatter.format_text(result, args.verbose, output_file, issue_filter)

        print(report)

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–¥ –≤—ã—Ö–æ–¥–∞
        if result.stats.get('error_count', 0) > 0:
            sys.exit(1)
        else:
            sys.exit(0)

    except KeyboardInterrupt:
        print("\n\n‚èπÔ∏è  –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(130)
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(2)



if __name__ == "__main__":
    main()
